name: validate
version: 1.0.0
description: |
  Validation and evaluation framework with pluggable evaluators.

  Evaluator types:
  - rule: Custom rule-based validation using JavaScript expressions
  - judge: LLM-based quality assessment (requires AI binding)
  - nlp: Statistical NLP metrics (BLEU, ROUGE, length ratio)
  - embedding: Semantic similarity via embeddings (requires AI binding)

operation: code
handler: ./validate.ts

tags:
  - validate
  - evaluation
  - quality
  - nlp

schema:
  input:
    type: object
    required: [content]
    properties:
      content:
        type: string
        description: Content to validate
      reference:
        type: string
        description: Reference text for comparison (NLP/embedding evaluators)
      expected:
        description: Expected value for exact comparison

  output:
    type: object
    properties:
      passed:
        type: boolean
        description: Whether content passed the threshold
      score:
        type: number
        minimum: 0
        maximum: 1
        description: Average score across all criteria
      scores:
        type: object
        additionalProperties:
          type: number
        description: Individual scores by criterion name
      details:
        type: object
        description: Additional details per evaluator
      evalType:
        type: string
        enum: [rule, judge, nlp, embedding]

config:
  schema:
    type: object
    properties:
      evalType:
        type: string
        enum: [rule, judge, nlp, embedding]
        default: rule
        description: Type of evaluator to use
      threshold:
        type: number
        default: 0.7
        minimum: 0
        maximum: 1
        description: Minimum score to pass
      rules:
        type: array
        items:
          type: object
          required: [name, check, weight]
          properties:
            name:
              type: string
            check:
              type: string
              description: JavaScript expression to evaluate
            weight:
              type: number
            description:
              type: string
        description: Rules for rule evaluator
      criteria:
        type: array
        items:
          type: object
          required: [name, weight]
          properties:
            name:
              type: string
            description:
              type: string
            weight:
              type: number
        description: Criteria for judge evaluator
      metrics:
        type: array
        items:
          type: string
          enum: [bleu, rouge, length-ratio]
        default: [bleu, rouge]
        description: NLP metrics to calculate
      reference:
        type: string
        description: Default reference text
      model:
        type: string
        description: Model for judge/embedding evaluators

examples:
  - name: rule-validation
    description: Validate content using rules
    input:
      content: "This is a detailed explanation of the topic that covers all important points."
    config:
      evalType: rule
      threshold: 0.7
      rules:
        - name: min_length
          check: "content.length >= 50"
          weight: 1
          description: "Content must be at least 50 characters"
        - name: has_explanation
          check: "content.includes('explanation')"
          weight: 1
          description: "Must mention explanation"
    output:
      passed: true
      score: 1.0
      scores:
        min_length: 1
        has_explanation: 1
      evalType: rule

  - name: nlp-comparison
    description: Compare content using NLP metrics
    input:
      content: "The quick brown fox jumps over the lazy dog."
      reference: "A fast brown fox leaps over a sleepy dog."
    config:
      evalType: nlp
      threshold: 0.5
      metrics: [bleu, rouge]
    output:
      passed: true
      score: 0.65
      scores:
        bleu: 0.55
        rouge: 0.75
      evalType: nlp
